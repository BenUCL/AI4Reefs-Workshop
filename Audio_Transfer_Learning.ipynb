{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNTyfg5NA9+UgzBb0C0jrEI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BenUCL/AI4Reefs-Workshop/blob/main/Audio_Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Machine learning with coral reef soundscape data**\n",
        "\n",
        "We're going to use audio data you accessed in the introductory colab. This includes 151 one-minute audio files from healthy and degraded reefs in Indonesia.\n",
        "\n",
        "Follow these steps:\n",
        "- First, run the code up to the end of Step 1. Let the neural net extract features from the first several audio files and note the speed of this.\n",
        "- Now, switch to a GPU runtime. This should be lightning fast compared to the original execution. Let the feature extraction run to completion.\n",
        "\n",
        "# **Step 1: Feature extraction**\n",
        "ADD NOTES ON, it cuts audio into 0.96s\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Rp2afetqTiIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports\n",
        "import os # for handling files and directories\n",
        "import librosa # for audio processing\n",
        "import tensorflow as tf # for machine learning\n",
        "import tensorflow_hub as hub # for machine learning\n",
        "import numpy as np # for numerical processing\n",
        "import pandas as pd # for handling dataframes\n",
        "from tqdm import tqdm # for progress bar"
      ],
      "metadata": {
        "id": "KjPL_e_JC49V"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mount your drive and add the path to the audio data once again"
      ],
      "metadata": {
        "id": "jrBAdEmxVLre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Directory containing audio files\n",
        "#audio_dir = 'ADD PATH HERE'\n",
        "audio_dir = '/content/drive/MyDrive/Reef soundscapes with AI/audio_dir'\n"
      ],
      "metadata": {
        "id": "cPYVJFJ290Nm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load the VGGish model\n",
        "model = hub.load('https://www.kaggle.com/models/google/vggish/frameworks/TensorFlow2/variations/vggish/versions/1')"
      ],
      "metadata": {
        "id": "NxYu8oLwC4E1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract features with the neural net\n",
        "\n",
        "Now we run the main for loop to iterate over each file extract features using the pretrained neruel network.\n",
        "\n",
        "To speed things up, we only use 40 healthy and 40 degraded files.\n",
        "\n",
        "The results will be saved to a 'pandas dataframe', similar to a dataframe in R, and, to the 'extracted_features.csv' which should appear in the file tab on the left.\n",
        "\n",
        "While the code is running, take a look at it and see how much you can understand. Try asking Chatgpt or Claude to explain parts you don't understand."
      ],
      "metadata": {
        "id": "9Ri9SsmLWzFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract class from filename\n",
        "def get_class(filename):\n",
        "    if 'D' in filename:\n",
        "        return 'degraded'\n",
        "    elif 'H' in filename:\n",
        "        return 'healthy'\n",
        "    else:\n",
        "        return 'unknown'\n",
        "\n",
        "# Function to exctract features audio files and save these to a df\n",
        "def process_audio_files(audio_dir, model):\n",
        "\n",
        "    # List to store ouputs\n",
        "    rows_list = []\n",
        "    # Create outputs in loop\n",
        "    for filename in tqdm(os.listdir(audio_dir), desc=\"Processing audio files\"):\n",
        "        if filename.endswith('.wav'):\n",
        "            file_class = get_class(filename)\n",
        "\n",
        "            # Process the file\n",
        "            file_path = os.path.join(audio_dir, filename)\n",
        "            audio, _ = librosa.load(file_path, sr=16000)\n",
        "            vggish_features = model(audio).numpy()\n",
        "\n",
        "            for i, embedding in enumerate(vggish_features):\n",
        "                # Splitting the filename and embedding index\n",
        "                embedding_index = i + 1\n",
        "                row_data = {'filename': filename, 'embedding_index': embedding_index, 'class': file_class}\n",
        "                for j, feature in enumerate(embedding):\n",
        "                    row_data[f'feature_{j}'] = feature\n",
        "                rows_list.append(row_data)\n",
        "\n",
        "    # Create DataFrame from the list\n",
        "    results_df = pd.DataFrame(rows_list)\n",
        "    return results_df\n",
        "\n",
        "# Process the audio files\n",
        "results_df = process_audio_files(audio_dir, model)\n",
        "\n",
        "# Save the results to a CSV file\n",
        "results_df.to_csv('/content/extracted_features.csv', index=False)"
      ],
      "metadata": {
        "id": "a4URum2earG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you're done with the GPU on colab, its good practice to switch back to a standard runtime. Make sure to download the extracted_features.csv first! You can then re-upload this to your new runtime."
      ],
      "metadata": {
        "id": "asMls6oWyIQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Take a peek at the dataframe\n",
        "\n",
        "# Load the csv as a dataframe\n",
        "df = pd.read_csv('ADD PATH')\n",
        "\n",
        "# We add another column that encodes classes as integers for later\n",
        "class_mapping = {'healthy': 1, 'degraded': 0}\n",
        "df['encoded_class'] = df['class'].map(class_mapping)\n",
        "\n",
        "# Place 'encoded_class' next to the 'class' column\n",
        "cols = df.columns.tolist()\n",
        "class_index = cols.index('class')\n",
        "cols.insert(class_index + 1, cols.pop(cols.index('encoded_class')))\n",
        "df = df[cols]\n",
        "\n",
        "# Display the DataFrame to see the new column\n",
        "df"
      ],
      "metadata": {
        "id": "YBouf3FFZ34w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use colab to plot the df\n",
        "\n",
        "Scroll to the right of the df table and you should see the plotting symbol in the top right.\n",
        "\n",
        "Lets make a plot that shows the distribution of classes.\n",
        "\n",
        "Questions\n",
        "1. What is the approximate ratio of healthy or degreded?\n",
        "2. How might this affect the metric we use for assessing a supervised classifer?\n",
        "\n",
        "\n",
        "\n",
        "## **Step 2: Cluster the data**\n",
        "\n",
        "Now we are going to perform unsupervised clustering. We'll start with k-means clustering. Like Random Forests for classification, this is always a safe bet to use for a first quick model.\n",
        "\n",
        "Start by looking at the scikit-learn documentation and try get a quick understanding of k-means (https://scikit-learn.org/stable/modules/clustering.html#k-means). Stuck on anything? Ask ChatGPT! Its knowledge on commonly used approaches like this is very reliable."
      ],
      "metadata": {
        "id": "lTUzvdYBMSBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set variables\n",
        "num_clusters = 2\n",
        "random_seed = 0\n",
        "\n",
        "# Select only the feature columns (assuming they are named 'feature_0', 'feature_1', ...)\n",
        "feature_cols = [col for col in df.columns if col.startswith('feature_')]\n",
        "X = df[feature_cols]\n",
        "\n",
        "# Apply k-means clustering\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=random_seed)\n",
        "clusters = kmeans.fit_predict(X)\n",
        "\n",
        "# Add the cluster information to the DataFrame\n",
        "df['cluster'] = clusters\n",
        "\n",
        "# Prepare data for the bar plot\n",
        "cluster_class_counts = df.groupby(['cluster', 'class']).size().unstack().fillna(0)\n",
        "\n",
        "# Create the bar plot\n",
        "cluster_class_counts.plot(kind='bar', stacked=True, color=['green', 'orange'])\n",
        "plt.xlabel('Cluster')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Cluster Distribution by Class')\n",
        "plt.legend(title='Class')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MCMwPjdAgVG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Questions\n",
        "1. Try varying the number of clusters. What are the benefits of setting less or more clusters?\n",
        "2. What can you intepret about how different healthy and degraded reefs sound by these results?\n",
        "2. We know whether audio came from healthy or degraded reefs. Why is unsupervised learning still useful in place of supervised learning here?\n",
        "3. HARDER: Now try using ChatGPT and/or the scikit learn clustering documentation (https://scikit-learn.org/stable/modules/clustering.html#k-means) to implement a different clustering algorithm. You will only need to modify the two lines of code underneath 'Apply k-means clustering'. Do this in a new cell below."
      ],
      "metadata": {
        "id": "x_OXNy_RZQ1R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 3: Dimensionality reduction and visualisation**\n",
        "\n",
        "We will use 'Uniform Manifold Approximation' (UMAP). Put simply, UMAP is able to reduce the dimensions of our data from the 128 VGGish outputs to something lower. It can go as low as two dimensions, allowing us to visualise this in 2D.\n",
        "\n",
        "This will plot recordings that sound similar cloe together, and recordings that sound different apart. Note it doesn't directly create clusters.\n",
        "\n",
        "UMAP is not a standard package on Colab so we need to start install it. This is typically using the terminal. We can use an '!' before code to run it as a terminal command."
      ],
      "metadata": {
        "id": "4pgfgMyUoAk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install UMAP\n",
        "!pip install umap-learn"
      ],
      "metadata": {
        "id": "pc5V3LDHpCB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now run UMAP\n",
        "\n",
        "We pass UMAP 'X' - can you see where is this coming from? What does X contain?\n",
        "\n",
        "UMAP take a minute or two..."
      ],
      "metadata": {
        "id": "nvk1IXippT4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import umap\n",
        "\n",
        "# n_neighbors and min_dist are important parameters, but we can use common defaults\n",
        "reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=random_seed)\n",
        "embedding = reducer.fit_transform(X)"
      ],
      "metadata": {
        "id": "pfxRIv2WYA0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given the UMAP component takes longer to run. We produce the plot in a different cell to allow quicker edits to the plot."
      ],
      "metadata": {
        "id": "EHke5YrFqi-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the UMAP projection\n",
        "c = df['cluster']\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.scatter(embedding[:, 0], embedding[:, 1], c=c, cmap='Spectral', s=5)\n",
        "plt.colorbar(label='Cluster')\n",
        "plt.title('UMAP Projection of the Dataset')\n",
        "plt.xlabel('UMAP 1')\n",
        "plt.ylabel('UMAP 2')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Kl-CxQPcqiEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Questions / Exercises\n",
        "1. You can save the plot by right clicking and use this for comparing different version.\n",
        "2. Here we are seeing the points colour coded by 'cluster'. Try colour coding them by 'class'. How does this change the plot? Why is this?\n",
        "3. What if you produce more clusters in the k-means section and plot by cluster again?\n",
        "4. You might see some small groups of anomolies away from their main group. What could cause this?"
      ],
      "metadata": {
        "id": "e2zkTFaTqGJp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Advanced: Supervised learning**\n",
        "1. Take the feature variables created earlier from the df. Create a labels variable from the 'encoded_labels' column (use ChatGPT for help if needed). Check your labels variable looks correct.\n",
        "2. Now use and adapt the relevant code from the intro colab to train a random forest classifier and report the accuracy.\n",
        "3. This should be very accurate. Remember, we have 62 samples from each 1-min recording that likely sound similar. Why could this bias accuracy? How should we better handle this? Try using the 'groupby' function in pandas.\n",
        "4. Due to the small class imbalance, we might want a different metric to accuracy? Why is this? Try and find some contenders and implement one of these (ask ChatGPT for help).\n"
      ],
      "metadata": {
        "id": "Nll20B-uxWME"
      }
    }
  ]
}